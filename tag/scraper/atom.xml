<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: scraper | Edmonds Commerce Dev Blog]]></title>
  <link href="http://edmondscommerce.github.io/tag/scraper/atom.xml" rel="self"/>
  <link href="http://edmondscommerce.github.io/"/>
  <updated>2013-12-03T12:47:48+00:00</updated>
  <id>http://edmondscommerce.github.io/</id>
  <author>
    <name><![CDATA[EdmondsCommerce Development Team]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Apache Log File Analysis Script]]></title>
    <link href="http://edmondscommerce.github.io/bash/apache-log-file-analysis-script.html"/>
    <updated>2013-03-14T14:17:48+00:00</updated>
    <id>http://edmondscommerce.github.io/bash/apache-log-file-analysis-script</id>
    <content type="html"><![CDATA[<p>Here is a little bash script we knocked together to track down some malicious activity on a clients server.</p>

<p>Using a bit of awk etc to parse the log files we could quickly track down an IP address that was overloading the server and then take steps to block that person.</p>

<p>Here is the script:</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<h6>SETUP</h6>

<p>LOG_FOLDER=/var/www/vhosts/domain.co.uk/statistics/logs
ACCESS_LOG=$LOG_FOLDER/access_log</p>

<p>HOW_MANY_ROWS=20000</p>

<h6>### FUNCTIONS</h6>

<p>function title() {</p>

<pre><code>echo "
</code></pre>

<hr />

<h2>$@</h2>

<p>&ldquo;
}</p>

<p>function urls_by_ip() {</p>

<pre><code>local IP=$1
tail -5000 $ACCESS_LOG | awk -v ip=$IP ' $1 ~ ip {freq[$7]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20
</code></pre>

<p>}</p>

<p>function ip_addresses_by_user_agent(){</p>

<pre><code>local USERAGENT_STRING="$1"
local TOP_20_IPS="`tail  -$HOW_MANY_ROWS $ACCESS_LOG | grep "${USERAGENT_STRING}"  | awk '{freq[$1]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20`"
echo "$TOP_20_IPS"
</code></pre>

<p>}</p>

<h6># RUN REPORTS</h6>

<p>title &ldquo;top 20 URLs&rdquo;
TOP_20_URLS=&ldquo;<code>tail -$HOW_MANY_ROWS $ACCESS_LOG | awk '{freq[$7]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20</code>&rdquo;
echo &ldquo;$TOP_20_URLS&rdquo;</p>

<p>title &ldquo;top 20 URLS excluding POST data&rdquo;
TOP_20_URLS_WITHOUT_POST=&ldquo;<code>tail  -$HOW_MANY_ROWS $ACCESS_LOG | awk -F"[ ?]" '{freq[$7]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20</code>&rdquo;
echo &ldquo;$TOP_20_URLS_WITHOUT_POST&rdquo;</p>

<p>title &ldquo;top 20 IPs&rdquo;
TOP_20_IPS=&ldquo;<code>tail  -$HOW_MANY_ROWS $ACCESS_LOG | awk '{freq[$1]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20</code>&rdquo;
echo &ldquo;$TOP_20_IPS&rdquo;</p>

<p>title &ldquo;top 20 user agents&rdquo;
TOP_20_USER_AGENTS=&ldquo;<code>tail  -$HOW_MANY_ROWS $ACCESS_LOG | cut -d\  -f12- | sort | uniq -c | sort -rn | head -20</code>&rdquo;
echo &ldquo;$TOP_20_USER_AGENTS&rdquo;</p>

<p>title &ldquo;IP Addresses for Top 3 User Agents&rdquo;</p>

<p>for ((I=1; I&lt;=3; I++))
do</p>

<pre><code>UA="`echo "$TOP_20_USER_AGENTS" | head -n $I | tail -n 1 | awk '{$1=""; print $0}'`"
echo "$UA"
echo "~~~~~~~~~~~~~~~~~~"
ip_addresses_by_user_agent "$UA"
echo "
"
</code></pre>

<p>done</p>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple PHP Scraping with jQuery Like Selectors using Simple HTML Dom]]></title>
    <link href="http://edmondscommerce.github.io/scraping/simple-php-scraping-with-jquery-like-selectors-using-simpledom.html"/>
    <updated>2012-08-21T18:29:43+01:00</updated>
    <id>http://edmondscommerce.github.io/scraping/simple-php-scraping-with-jquery-like-selectors-using-simpledom</id>
    <content type="html"><![CDATA[<p>If you need to do some HTML parsing, scraping etc then you generally have the choice of using the DOM approach to parse the HTML or using regex to pull bits out. I quite like both approaches, there are pros and cons to both so having both options available is the best to ensure you use the right tool for the job on a case by case basis.</p>

<p>Recently though I discovered Simple HTML Dom. This makes the DOM based approach almost ridiculously easy, especially if you are comfortable with jQuery like selectors for pulling out specific DOM nodes.</p>

<p>You can read all about it here:
<a href="http://simplehtmldom.sourceforge.net/manual.htm" title="Simple HTML Dom" target="_blank"><a href="http://simplehtmldom.sourceforge.net/manual.htm">http://simplehtmldom.sourceforge.net/manual.htm</a></a></p>

<p>First impressions are really good, its very easy and the lead in time from installation to using is really fast. I like that, never been much of a fan of having to RTFM for everything!</p>
]]></content>
  </entry>
  
</feed>
