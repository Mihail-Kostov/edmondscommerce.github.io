<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: linux | Edmonds Commerce Dev Blog]]></title>
  <link href="http://edmondscommerce.github.io/tag/linux/atom.xml" rel="self"/>
  <link href="http://edmondscommerce.github.io/"/>
  <updated>2014-04-28T13:25:53+01:00</updated>
  <id>http://edmondscommerce.github.io/</id>
  <author>
    <name><![CDATA[EdmondsCommerce Development Team]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[GoAccess - Nice CLI Access Log Parsing Tool (and how to install on CentOS)]]></title>
    <link href="http://edmondscommerce.github.io/sysadmin/goaccess-nice-cli-access-log-parsing-tool-and-how-to-install-on-centos.html"/>
    <updated>2014-04-24T12:40:27+01:00</updated>
    <id>http://edmondscommerce.github.io/sysadmin/goaccess-nice-cli-access-log-parsing-tool-and-how-to-install-on-centos</id>
    <content type="html"><![CDATA[<p>Log files are probably the single most useful item on a web server when it comes to debugging. They are packed full of all the information you need to understand what is
happening on the server and detect any potential issues.</p>

<p>Reading log files by hand is basically imposssible for any meaningful overall monitoring. You can of course do some grepping and other bash tools to gain more insights but some times it&rsquo;s nice to just have a simple tool.</p>

<p>I am a big fan of tools like top, mytop, apachetop and ngxtop. GoAccess is a little bit different though, mainly it just seems a lot more fully featured.</p>

<p>Best thing to do is to try it. Here is how to install it on CentoOS</p>

<p>``` bash
yum install ncurses-devel glib2-devel geoip-devel
mkdir -p ~/goaccess
cd ~/goaccess
wget <a href="http://downloads.sourceforge.net/project/goaccess/0.7.1/goaccess-0.7.1.tar.gz">http://downloads.sourceforge.net/project/goaccess/0.7.1/goaccess-0.7.1.tar.gz</a>
tar -xzvf goaccess-0.7.1.tar.gz
cd goaccess-0.7.1/
./configure &mdash;enable-geoip &mdash;enable-utf8
make
make install</p>

<p>```</p>

<p>You can read more about GoAccess here:
<a href="http://goaccess.prosoftcorp.com/">http://goaccess.prosoftcorp.com/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bash Delete Everything But - Handy Function for your bashrc File]]></title>
    <link href="http://edmondscommerce.github.io/bash/bash-delete-everything-but-handy-function-for-your-bashrc-file.html"/>
    <updated>2014-04-11T11:23:16+01:00</updated>
    <id>http://edmondscommerce.github.io/bash/bash-delete-everything-but-handy-function-for-your-bashrc-file</id>
    <content type="html"><![CDATA[<p>For me the use case was a cache directory that I wanted to clear out everything apart from one particular file that was expensive
to create and didn&rsquo;t need to be cleared for my purposes</p>

<p>I decided to add this to my ~/.bashrc file for ease of use in future.</p>

<p>Here is the function</p>

<p>``` bash</p>

<h1>Remove Everything But</h1>

<p>function rmbut(){</p>

<pre><code>local BUT="$@"
ls | grep -v *$BUT* | while read f; do rm -rf $f; done
</code></pre>

<p>}
```</p>

<p>To use the function, simply <code>cd</code> to the directory you want to clear out and then call <code>rmbut MyFileIWantToKeep</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Pipe Viewer for an Easy CLI Progress Bar]]></title>
    <link href="http://edmondscommerce.github.io/linux/using-pipe-viewer-for-an-easy-cli-progress-bar.html"/>
    <updated>2014-03-17T14:58:14+00:00</updated>
    <id>http://edmondscommerce.github.io/linux/using-pipe-viewer-for-an-easy-cli-progress-bar</id>
    <content type="html"><![CDATA[<p>If you have a large database file to import or any other longer running process that involves piping data from one place to another then this little utility should definitely be in your arsenal.</p>

<p>Simply enough you use this to give you a progress indication when you are piping large amounts of data.</p>

<p>To use this on a mysql import (which is where I am most likely to use this) you would do the following:</p>

<p><code>bash
pv ./dumpfile.sql | mysql -u$USER -p$PASS dbname
</code></p>

<p>This will then give you a simple progress bar and very usefully, an ETA that indicates how much time is left For example:
<code>
 308MB 0:07:57 [ 216kB/s] [===============&gt;                                          ] 10% ETA 1:08:32
</code></p>

<p>To install the utility you should first of all just try <code>yum install pv</code>. If that doesn&rsquo;t work then you can read more about installing for your distribution here:
<a href="http://www.ivarch.com/programs/pv.shtml">http://www.ivarch.com/programs/pv.shtml</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Finding out the biggest folders in a Magento or other website root]]></title>
    <link href="http://edmondscommerce.github.io/bash/finding-out-the-biggest-folders-in-a-magento-or-other-website-root.html"/>
    <updated>2014-03-04T16:10:19+00:00</updated>
    <id>http://edmondscommerce.github.io/bash/finding-out-the-biggest-folders-in-a-magento-or-other-website-root</id>
    <content type="html"><![CDATA[<p>Often pulling down a Magento or other site you&rsquo;ll find a load of files that have been dumped in the web root. Downloading these is often pointless and takes extra time, so you&rsquo;ll want to exclude them from an rsync (using the <code>--exclude 'path'</code> paramter).</p>

<p>A simple bash command for this is:</p>

<p>```bash</p>

<p>du -m &mdash;max-depth=1 &mdash;exclude media | sort -n</p>

<p>```</p>

<p>This invokes <code>du</code> to show each direct subfolder&rsquo;s contents' size, and pipes it through to <code>sort</code> to rank them in increasing size. The sizes are in MB. See <a href="http://explainshell.com/explain?cmd=du+-m+--max-depth%3D1+--exclude+media+|+sort+-n">a more broken down explanation here</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[cPanel Download Site Files and Database]]></title>
    <link href="http://edmondscommerce.github.io/cpanel/cpanel-download-site-files-and-database.html"/>
    <updated>2014-02-10T18:03:36+00:00</updated>
    <id>http://edmondscommerce.github.io/cpanel/cpanel-download-site-files-and-database</id>
    <content type="html"><![CDATA[<p>Often a client won&rsquo;t have access to SSH, or won&rsquo;t be able to provide you with some of the more specifics such as FTP, PHPMyAdmin etc. All they know to give you is access to their cPanel. Through this there&rsquo;s various tools at your disposal.</p>

<h2>Try SSH</h2>

<p>Your cPanel login is actually a Linux user login, which cPanel&rsquo;s FTP hooks into. The first step is to navigate in your cPanel to FTP Accounts and click Configure FTP client on a user. These are SFTP details and can very often provide you with SSH shell access, unless the host has disabled this.</p>

<p>Simply try <code>ssh user@host -p 1234</code>, where the user, host and password are your cPanel login, and the port displayed on the FTP Accounts page.</p>

<p>From here you&rsquo;re free to use <code>tar</code>, <code>gzip</code>, <code>mysqldump</code> etc to acquire the files and database.</p>

<h2>If SSH isn&rsquo;t enabled</h2>

<p>Sometimes the host disables SSH access, only allowing its use for SFTP. There are still many ways to acquire the site&rsquo;s files and database:</p>

<h3>Getting hold of the files</h3>

<ul>
<li><strong>Plain old FTP</strong> &ndash; You can just use an FTP client such as Filezilla to access and download the site&rsquo;s files using FTP or SFTP. This is the simplest way, but can take a long time because of the amount of files involved</li>
<li><strong>File Manager Web UI</strong> &ndash; compressing the site&rsquo;s files obviously shrinks the download size, but also vastly reduces the amount of connections you need to make, leading to a faster download speed.

<ol>
<li> Navigate to the File Manager section (remember to tick &ldquo;Show hidden files&rdquo; to pick up .htaccess files)</li>
<li>Browse to the web root folder, select all the files and folders you want using Ctrl+Click. Remember to exclude unnecessary large files such as sql dumps, media folders and the var folder</li>
<li>Click Compress from the toolbar</li>
</ol>
</li>
</ul>


<h3>Getting hold of the database</h3>

<ul>
<li><strong>PHPMyAdmin</strong> &ndash; PHPMyAdmin offers an array of options for dumping your database. You should start by checking the database&rsquo;s size and considering excluding the dump of tables such as <code>log_url</code>, <code>log_url_info</code>, <code>log_visitor</code>, <code>log_visitor_info</code>, <code>report_viewed_product_index</code>

<ol>
<li> Navigate to the PHPMyAdmin area of cPanel and locate the database in use (check your <code>app/etc/local.xml</code> if you&rsquo;re not sure which</li>
<li>Click the Export tab</li>
<li>Select Custom: here&rsquo;s where you can selectively export information</li>
<li>Tick &lsquo;Disable foreign key checks&rsquo; and set &lsquo;Dump table&rsquo; to &lsquo;structure&rsquo;. This will have PHPMyAdmin set up only the tables' columns but no data (we&rsquo;ll get to that)</li>
<li>Click Go</li>
<li>Once this is complete, navigate back to the Export page and click Custom again.</li>
<li>Deselect (ctrl+click) any tables which are unnecessary</li>
<li>Tick &lsquo;Disable foreign key checks&rsquo; and set &lsquo;Dump table&rsquo; this time to &lsquo;data&rsquo;</li>
<li>This will provide you with two files representing the database. Import first the Structure one, and then the Data one (or concatenate the two together)</li>
</ol>
</li>
</ul>

]]></content>
  </entry>
  
</feed>
