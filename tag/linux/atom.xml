<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: linux | Edmonds Commerce Dev Blog]]></title>
  <link href="http://edmondscommerce.github.io/tag/linux/atom.xml" rel="self"/>
  <link href="http://edmondscommerce.github.io/"/>
  <updated>2014-06-09T16:11:23+01:00</updated>
  <id>http://edmondscommerce.github.io/</id>
  <author>
    <name><![CDATA[EdmondsCommerce Development Team]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Apache JMeter For Load Testing]]></title>
    <link href="http://edmondscommerce.github.io/load%20testing/using-apache-jmeter-for-load-testing.html"/>
    <updated>2014-05-27T13:01:39+01:00</updated>
    <id>http://edmondscommerce.github.io/load%20testing/using-apache-jmeter-for-load-testing</id>
    <content type="html"><![CDATA[<p>Load testing is something that you really need a decent solution for. A simple tool such as Apache Bench (ab) is overly simplistic for todays web applications.</p>

<p>After some research I decided to use Apache Jmeter as the tool of choice. It is written in Java so easy enough to run on any platform.
It features a GUI which is ideal for creating your tests, then a command line version which is what you should use to run your tests.</p>

<p>For my purposes I wanted to feed in a large list of URLs, for that I followed these instructions:
<a href="http://asciiville.com/musings/coder/how-to-feed-jmeter-from-csv">http://asciiville.com/musings/coder/how-to-feed-jmeter-from-csv</a></p>

<p>This allows you to create a csv file with your choice of URLs. It was actually quite hard to find a decent and succint guide to getting this set up but thankfully that page fitted my requirements.</p>

<p>Once I started to run the test I quickly realised that my system was grinding to a halt with out of memory errors. A bit more searching yielded this page which advises on how to properly run Jmeter including the fact that you really should run it on the command line for proper testing.
<a href="http://blazemeter.com/blog/jmeter-performance-and-tuning-tips">http://blazemeter.com/blog/jmeter-performance-and-tuning-tips</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GoAccess - Nice CLI Access Log Parsing Tool (and how to install on CentOS)]]></title>
    <link href="http://edmondscommerce.github.io/sysadmin/goaccess-nice-cli-access-log-parsing-tool-and-how-to-install-on-centos.html"/>
    <updated>2014-04-24T12:40:27+01:00</updated>
    <id>http://edmondscommerce.github.io/sysadmin/goaccess-nice-cli-access-log-parsing-tool-and-how-to-install-on-centos</id>
    <content type="html"><![CDATA[<p>Log files are probably the single most useful item on a web server when it comes to debugging. They are packed full of all the information you need to understand what is
happening on the server and detect any potential issues.</p>

<p>Reading log files by hand is basically imposssible for any meaningful overall monitoring. You can of course do some grepping and other bash tools to gain more insights but some times it&rsquo;s nice to just have a simple tool.</p>

<p>I am a big fan of tools like top, mytop, apachetop and ngxtop. GoAccess is a little bit different though, mainly it just seems a lot more fully featured.</p>

<p>Best thing to do is to try it. Here is how to install it on CentoOS</p>

<p>``` bash
yum install ncurses-devel glib2-devel geoip-devel
mkdir -p ~/goaccess
cd ~/goaccess
wget <a href="http://downloads.sourceforge.net/project/goaccess/0.7.1/goaccess-0.7.1.tar.gz">http://downloads.sourceforge.net/project/goaccess/0.7.1/goaccess-0.7.1.tar.gz</a>
tar -xzvf goaccess-0.7.1.tar.gz
cd goaccess-0.7.1/
./configure &mdash;enable-geoip &mdash;enable-utf8
make
make install</p>

<p>```</p>

<p>You can read more about GoAccess here:
<a href="http://goaccess.prosoftcorp.com/">http://goaccess.prosoftcorp.com/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bash Delete Everything But - Handy Function for your bashrc File]]></title>
    <link href="http://edmondscommerce.github.io/bash/bash-delete-everything-but-handy-function-for-your-bashrc-file.html"/>
    <updated>2014-04-11T11:23:16+01:00</updated>
    <id>http://edmondscommerce.github.io/bash/bash-delete-everything-but-handy-function-for-your-bashrc-file</id>
    <content type="html"><![CDATA[<p>For me the use case was a cache directory that I wanted to clear out everything apart from one particular file that was expensive
to create and didn&rsquo;t need to be cleared for my purposes</p>

<p>I decided to add this to my ~/.bashrc file for ease of use in future.</p>

<p>Here is the function</p>

<p>``` bash</p>

<h1>Remove Everything But</h1>

<p>function rmbut(){</p>

<pre><code>local BUT="$@"
ls | grep -v *$BUT* | while read f; do rm -rf $f; done
</code></pre>

<p>}
```</p>

<p>To use the function, simply <code>cd</code> to the directory you want to clear out and then call <code>rmbut MyFileIWantToKeep</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Pipe Viewer for an Easy CLI Progress Bar]]></title>
    <link href="http://edmondscommerce.github.io/linux/using-pipe-viewer-for-an-easy-cli-progress-bar.html"/>
    <updated>2014-03-17T14:58:14+00:00</updated>
    <id>http://edmondscommerce.github.io/linux/using-pipe-viewer-for-an-easy-cli-progress-bar</id>
    <content type="html"><![CDATA[<p>If you have a large database file to import or any other longer running process that involves piping data from one place to another then this little utility should definitely be in your arsenal.</p>

<p>Simply enough you use this to give you a progress indication when you are piping large amounts of data.</p>

<p>To use this on a mysql import (which is where I am most likely to use this) you would do the following:</p>

<p><code>bash
pv ./dumpfile.sql | mysql -u$USER -p$PASS dbname
</code></p>

<p>This will then give you a simple progress bar and very usefully, an ETA that indicates how much time is left For example:
<code>
 308MB 0:07:57 [ 216kB/s] [===============&gt;                                          ] 10% ETA 1:08:32
</code></p>

<p>To install the utility you should first of all just try <code>yum install pv</code>. If that doesn&rsquo;t work then you can read more about installing for your distribution here:
<a href="http://www.ivarch.com/programs/pv.shtml">http://www.ivarch.com/programs/pv.shtml</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Finding out the biggest folders in a Magento or other website root]]></title>
    <link href="http://edmondscommerce.github.io/bash/finding-out-the-biggest-folders-in-a-magento-or-other-website-root.html"/>
    <updated>2014-03-04T16:10:19+00:00</updated>
    <id>http://edmondscommerce.github.io/bash/finding-out-the-biggest-folders-in-a-magento-or-other-website-root</id>
    <content type="html"><![CDATA[<p>Often pulling down a Magento or other site you&rsquo;ll find a load of files that have been dumped in the web root. Downloading these is often pointless and takes extra time, so you&rsquo;ll want to exclude them from an rsync (using the <code>--exclude 'path'</code> paramter).</p>

<p>A simple bash command for this is:</p>

<p>```bash</p>

<p>du -m &mdash;max-depth=1 &mdash;exclude media | sort -n</p>

<p>```</p>

<p>This invokes <code>du</code> to show each direct subfolder&rsquo;s contents' size, and pipes it through to <code>sort</code> to rank them in increasing size. The sizes are in MB. See <a href="http://explainshell.com/explain?cmd=du+-m+--max-depth%3D1+--exclude+media+|+sort+-n">a more broken down explanation here</a></p>
]]></content>
  </entry>
  
</feed>
