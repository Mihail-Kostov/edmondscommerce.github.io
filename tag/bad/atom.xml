<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: bad | Edmonds Commerce Dev Blog]]></title>
  <link href="http://edmondscommerce.github.io/tag/bad/atom.xml" rel="self"/>
  <link href="http://edmondscommerce.github.io/"/>
  <updated>2013-12-05T20:04:47+00:00</updated>
  <id>http://edmondscommerce.github.io/</id>
  <author>
    <name><![CDATA[EdmondsCommerce Development Team]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Apache Log File Analysis Script]]></title>
    <link href="http://edmondscommerce.github.io/bash/apache-log-file-analysis-script.html"/>
    <updated>2013-03-14T14:17:48+00:00</updated>
    <id>http://edmondscommerce.github.io/bash/apache-log-file-analysis-script</id>
    <content type="html"><![CDATA[<p>Here is a little bash script we knocked together to track down some malicious activity on a clients server.</p>

<p>Using a bit of awk etc to parse the log files we could quickly track down an IP address that was overloading the server and then take steps to block that person.</p>

<p>Here is the script:</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<h6>SETUP</h6>

<p>LOG_FOLDER=/var/www/vhosts/domain.co.uk/statistics/logs
ACCESS_LOG=$LOG_FOLDER/access_log</p>

<p>HOW_MANY_ROWS=20000</p>

<h6>### FUNCTIONS</h6>

<p>function title() {</p>

<pre><code>echo "
</code></pre>

<hr />

<h2>$@</h2>

<p>&ldquo;
}</p>

<p>function urls_by_ip() {</p>

<pre><code>local IP=$1
tail -5000 $ACCESS_LOG | awk -v ip=$IP ' $1 ~ ip {freq[$7]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20
</code></pre>

<p>}</p>

<p>function ip_addresses_by_user_agent(){</p>

<pre><code>local USERAGENT_STRING="$1"
local TOP_20_IPS="`tail  -$HOW_MANY_ROWS $ACCESS_LOG | grep "${USERAGENT_STRING}"  | awk '{freq[$1]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20`"
echo "$TOP_20_IPS"
</code></pre>

<p>}</p>

<h6># RUN REPORTS</h6>

<p>title &ldquo;top 20 URLs&rdquo;
TOP_20_URLS=&ldquo;<code>tail -$HOW_MANY_ROWS $ACCESS_LOG | awk '{freq[$7]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20</code>&rdquo;
echo &ldquo;$TOP_20_URLS&rdquo;</p>

<p>title &ldquo;top 20 URLS excluding POST data&rdquo;
TOP_20_URLS_WITHOUT_POST=&ldquo;<code>tail  -$HOW_MANY_ROWS $ACCESS_LOG | awk -F"[ ?]" '{freq[$7]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20</code>&rdquo;
echo &ldquo;$TOP_20_URLS_WITHOUT_POST&rdquo;</p>

<p>title &ldquo;top 20 IPs&rdquo;
TOP_20_IPS=&ldquo;<code>tail  -$HOW_MANY_ROWS $ACCESS_LOG | awk '{freq[$1]++} END {for (x in freq) {print freq[x], x}}' | sort -rn | head -20</code>&rdquo;
echo &ldquo;$TOP_20_IPS&rdquo;</p>

<p>title &ldquo;top 20 user agents&rdquo;
TOP_20_USER_AGENTS=&ldquo;<code>tail  -$HOW_MANY_ROWS $ACCESS_LOG | cut -d\  -f12- | sort | uniq -c | sort -rn | head -20</code>&rdquo;
echo &ldquo;$TOP_20_USER_AGENTS&rdquo;</p>

<p>title &ldquo;IP Addresses for Top 3 User Agents&rdquo;</p>

<p>for ((I=1; I&lt;=3; I++))
do</p>

<pre><code>UA="`echo "$TOP_20_USER_AGENTS" | head -n $I | tail -n 1 | awk '{$1=""; print $0}'`"
echo "$UA"
echo "~~~~~~~~~~~~~~~~~~"
ip_addresses_by_user_agent "$UA"
echo "
"
</code></pre>

<p>done</p>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache Access Logs Find Spiders by Counting Requests to IP Addresses]]></title>
    <link href="http://edmondscommerce.github.io/linux/apache-access-logs-find-spiders-by-counting-requests-to-ip-addresses.html"/>
    <updated>2012-08-21T13:24:37+01:00</updated>
    <id>http://edmondscommerce.github.io/linux/apache-access-logs-find-spiders-by-counting-requests-to-ip-addresses</id>
    <content type="html"><![CDATA[<p>If you would like a quick summary of the IP addresses that are beating the **** out of your server by firing lots of requests for quite possibly malicious or otherwise nefarious reasons then try this little bash script:</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<p>LOG_FILE=/var/www/vhosts/DOMAIN.co.uk/statistics/logs/access_log
OUT_FILE=/tmp/spider_analysis</p>

<h1>This generates a file with the top 20 IP addresses by number of requests</h1>

<p>cat $LOG_FILE | awk &lsquo;{print $1}&rsquo; | sort | uniq -c | sort -nr | head -n 20 > $OUT_FILE</p>

<p>echo &ldquo;Top 20 IP addresses by number of request&rdquo;
cat $OUT_FILE</p>

<h1>allow for loop to split on new line</h1>

<p>IFS_BAK=$IFS
IFS=&ldquo;
&rdquo;</p>

<p>for i in <code>cat $OUT_FILE</code>
do</p>

<pre><code>COUNT=`echo $i | awk '{print $1}'`
IP_ADD=`echo $i | awk '{print $2}'`
echo ""
echo "---------------------------------"
echo ""
echo "$IP_ADD has made $COUNT requests"
echo "Whois Information"
whois $IP_ADD 
#lynx -dump http://who.cc/$IP_ADD # whois was blocked on the server i was using for some reason, use lynx as a work around
echo ""
echo "---------------------------------"
echo ""
</code></pre>

<p>done</p>

<h1>set that back</h1>

<p>IFS=$IFS_BAK
IFS_BAK=</p>

<p>```</p>

<p>You would use this to give you some idea of which IPs are hitting the server a lot.</p>

<p>Usually you would expect to see a lot of these being search engines which you likely want to allow. However if you see any domestic or other IP addresses then you may choose to block these.</p>
]]></content>
  </entry>
  
</feed>
