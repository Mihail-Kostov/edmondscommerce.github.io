<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mysqldump on Edmonds Commerce Dev Blog</title>
    <link>https://edmondscommerce.github.io/tags/mysqldump/</link>
    <description>Recent content in Mysqldump on Edmonds Commerce Dev Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Sep 2016 11:04:50 +0000</lastBuildDate>
    <atom:link href="https://edmondscommerce.github.io/tags/mysqldump/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Using Mysql Dump to Create Fixtures with Where Conditions</title>
      <link>https://edmondscommerce.github.io/using-mysql-dump-to-create-fixtures-with-where-conditions/</link>
      <pubDate>Thu, 29 Sep 2016 11:04:50 +0000</pubDate>
      
      <guid>https://edmondscommerce.github.io/using-mysql-dump-to-create-fixtures-with-where-conditions/</guid>
      <description>&lt;p&gt;When running unit tests it is generally advisable to have a test database that has a limited but known set of data.&lt;/p&gt;

&lt;p&gt;The idea is that before each test run, the test database is recreated. So that this process is not too slow we then tend to use a small subset of the real live database - perhaps 100 records or entities rather than however many are on the live site.&lt;/p&gt;

&lt;p&gt;In order to build this test database, we then use something call fixtures. This can be all kinds of things - some times the fixtures are created using PHP code. For absolute speed though, I prefer to use fixtures that are raw SQL files that can be very quickly loaded into a database.&lt;/p&gt;

&lt;p&gt;To create the fixtures, the very simplest way is to use &lt;code&gt;mysqldump&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;However, the issue with mysql dump in the way we normally use it is that it will dump an entire database - the opposite of what we are trying to achieve here.&lt;/p&gt;

&lt;p&gt;The trick here is to use the &lt;code&gt;--where&lt;/code&gt; option to mysqldump to limit the data that is actually dumped.&lt;/p&gt;

&lt;p&gt;Lets take a simple database with an &lt;code&gt;orders&lt;/code&gt;, &lt;code&gt;orders_products&lt;/code&gt; and an &lt;code&gt;orders_status_history table&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;First we will dump the orders into an SQL file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysqldump database_name  orders --where=&amp;quot;1 order by orders_id desc limit 0,100&amp;quot; --no-create-info &amp;gt; /tmp/orders.sql

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we need to calculate what the lowest order ID would be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lowestOrderId=$(mysql -N database_name -e &amp;quot;select min(t.orders_id) from (select orders_id from orders order by orders_id DESC limit 0,100) as t&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can run mysqldump on the other tables and dump their data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysqldump database_name  orders_products --where=&amp;quot;orders_id &amp;gt; $lowestOrderId&amp;quot; --no-create-info &amp;gt;&amp;gt; /tmp/orders.sql


mysqldump database_name  orders_status_history --where=&amp;quot;orders_id &amp;gt; $lowestOrderId&amp;quot; --no-create-info &amp;gt;&amp;gt; /tmp/orders.sql

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And thats it, you now have an orders.sql file with the data for your 100 most recent orders in a format that can easily be imported into a test database simple with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
mysql test_db_name &amp;lt; orders.sql

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>mysql_dump not restored correctly 1064: USING BTREE &#43; fix</title>
      <link>https://edmondscommerce.github.io/mysql/mysql_dump-not-restored-correctly-1064-using-btree-fix.html</link>
      <pubDate>Thu, 10 Nov 2011 18:30:05 +0000</pubDate>
      
      <guid>https://edmondscommerce.github.io/mysql/mysql_dump-not-restored-correctly-1064-using-btree-fix.html</guid>
      <description>&lt;p&gt;&lt;div class=&#34;oldpost&#34;&gt;&lt;h4&gt;This is post is now quite old and the the information it contains may be out of date or innacurate.&lt;/h4&gt;
&lt;p&gt;
If you find any errors or have any suggestions to update the information &lt;a href=&#34;http://edmondscommerce.github.io/contact-us/index.html&#34;&gt;please let us know&lt;/a&gt;
or &lt;a href=&#34;https://github.com/edmondscommerce/edmondscommerce.github.io&#34;&gt;create a pull request on GitHub&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;
When migrating one server to another you often hit bumps in the road.  Todays was transferring a database from one server to another.&lt;/p&gt;

&lt;p&gt;During this standard procedure I found that the restored database was missing a few tables.  Irritating as Magento doesn&amp;rsquo;t like missing tables.&lt;/p&gt;

&lt;p&gt;Digging down into the backup and extracting the first missing table I was able to replicate the error which came out as
&lt;code&gt;1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &amp;lsquo;USING BTREE&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;I eventually found out that some versions of mysql 5.1 export a dump file that contains mysql5.1 specific features and loading the file into mysql 5.0 will not work.&lt;/p&gt;

&lt;p&gt;The solution is a little frustrating but if you run the command with the &amp;ndash;compatible=mysql40 switch, the dump file extracts fine :-
&lt;code&gt;mysqldump &amp;ndash;compatible=mysql40&lt;/code&gt;
Don&amp;rsquo;t ask me why there&amp;rsquo;s no &amp;ndash;compatible=mysql50 flag.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>